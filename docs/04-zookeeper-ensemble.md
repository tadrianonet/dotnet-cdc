# Zookeeper Ensemble: Coordena√ß√£o Distribu√≠da

## Diagrama de Sequ√™ncia - Zookeeper Coordination

```mermaid
sequenceDiagram
    participant K1 as Kafka Broker 1
    participant K2 as Kafka Broker 2  
    participant K3 as Kafka Broker 3
    participant ZK1 as Zookeeper 1<br/>Leader
    participant ZK2 as Zookeeper 2<br/>Follower
    participant ZK3 as Zookeeper 3<br/>Follower
    participant Client as .NET Client

    Note over ZK1,ZK3: 1. Inicializa√ß√£o do Ensemble
    ZK1->>ZK2: Leader Election
    ZK1->>ZK3: Leader Election  
    ZK2-->>ZK1: Vote for Leader
    ZK3-->>ZK1: Vote for Leader
    ZK1->>ZK1: Become Leader

    Note over K1,ZK3: 2. Registro dos Brokers
    K1->>ZK1: Register /brokers/ids/1
    ZK1->>ZK2: Replicate znode
    ZK1->>ZK3: Replicate znode
    ZK2-->>ZK1: ACK
    ZK3-->>ZK1: ACK
    ZK1-->>K1: Registration confirmed

    K2->>ZK1: Register /brokers/ids/2
    K3->>ZK1: Register /brokers/ids/3
    
    Note over K1,ZK3: 3. Cria√ß√£o de T√≥pico
    Client->>K1: Create topic "eventos-paralelos"<br/>partitions=3, replication=3
    K1->>ZK1: Write /brokers/topics/eventos-paralelos
    ZK1->>ZK2: Replicate topic metadata
    ZK1->>ZK3: Replicate topic metadata
    
    K1->>ZK1: Write partition assignments<br/>/brokers/topics/eventos-paralelos/partitions
    ZK1->>K2: Notify partition assignment
    ZK1->>K3: Notify partition assignment

    Note over K1,ZK3: 4. Leader Election para Parti√ß√µes
    ZK1->>K1: Elect as leader for partition 0
    ZK1->>K2: Elect as leader for partition 1  
    ZK1->>K3: Elect as leader for partition 2
    
    K1->>ZK1: Update ISR for partition 0
    K2->>ZK1: Update ISR for partition 1
    K3->>ZK1: Update ISR for partition 2

    Note over K1,ZK3: 5. Monitoramento e Heartbeat
    loop Continuous Monitoring
        K1->>ZK1: Heartbeat (session renewal)
        K2->>ZK1: Heartbeat
        K3->>ZK1: Heartbeat
        ZK1->>ZK2: Sync heartbeat status
        ZK1->>ZK3: Sync heartbeat status
    end

    Note over K1,ZK3: 6. Falha e Recupera√ß√£o
    K2->>X: Broker 2 fails
    ZK1->>ZK1: Detect session timeout
    ZK1->>K1: Trigger rebalance
    ZK1->>K3: Trigger rebalance
    K1->>ZK1: Elect new leader for partition 1
    ZK1->>ZK3: Update ISR (remove broker 2)

    Note over K1,ZK3: 7. Configura√ß√£o Distribu√≠da
    Client->>ZK1: Update /config/topics/eventos-paralelos
    ZK1->>ZK2: Replicate config change
    ZK1->>ZK3: Replicate config change
    ZK1->>K1: Notify config change
    ZK1->>K3: Notify config change
```

## Estrutura de Dados Zookeeper

### üå≥ **√Årvore de Znodes Kafka**
```
/
‚îú‚îÄ‚îÄ brokers/
‚îÇ   ‚îú‚îÄ‚îÄ ids/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1 ‚Üí {"host":"kafka1","port":29092}
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2 ‚Üí {"host":"kafka2","port":29092}  
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 3 ‚Üí {"host":"kafka3","port":29092}
‚îÇ   ‚îú‚îÄ‚îÄ topics/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ eventos-paralelos/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ partitions/
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ 0/
‚îÇ   ‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ state ‚Üí {"leader":1,"isr":[1,2,3]}
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ 1/
‚îÇ   ‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ state ‚Üí {"leader":2,"isr":[1,2,3]}
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ 2/
‚îÇ   ‚îÇ               ‚îî‚îÄ‚îÄ state ‚Üí {"leader":3,"isr":[1,2,3]}
‚îú‚îÄ‚îÄ controller/
‚îÇ   ‚îî‚îÄ‚îÄ epoch ‚Üí {"brokerid":1,"epoch":1}
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ topics/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ eventos-paralelos ‚Üí {"retention.ms":"604800000"}
‚îÇ   ‚îî‚îÄ‚îÄ brokers/
‚îÇ       ‚îî‚îÄ‚îÄ 1 ‚Üí {"log.retention.hours":"168"}
‚îî‚îÄ‚îÄ consumers/
    ‚îî‚îÄ‚îÄ analytics-processor-dotnet/
        ‚îú‚îÄ‚îÄ owners/
        ‚îî‚îÄ‚îÄ offsets/
```

## Configura√ß√£o do Ensemble

### ‚öôÔ∏è **Docker Compose - Zookeeper Cluster**
```yaml
version: '3.8'
services:
  zk1:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zk1
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_SERVERS: zk1:2888:3888;zk2:2888:3888;zk3:2888:3888

  zk2:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zk2
    ports:
      - "2182:2181"
    environment:
      ZOOKEEPER_SERVER_ID: 2
      # ... mesmas configura√ß√µes com SERVER_ID diferente

  zk3:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zk3  
    ports:
      - "2183:2181"
    environment:
      ZOOKEEPER_SERVER_ID: 3
      # ... mesmas configura√ß√µes com SERVER_ID diferente
```

### üîß **Par√¢metros de Configura√ß√£o**

#### **Timing**
- `TICK_TIME: 2000`: Unidade b√°sica de tempo (2s)
- `INIT_LIMIT: 5`: Timeout para followers conectarem (10s)
- `SYNC_LIMIT: 2`: Timeout para sincroniza√ß√£o (4s)

#### **Cluster**
- `SERVER_ID`: Identificador √∫nico do servidor
- `SERVERS`: Lista de todos os servidores do ensemble
- `CLIENT_PORT`: Porta para clientes (2181)

#### **Comunica√ß√£o**
- `2888`: Porta para comunica√ß√£o entre servidores
- `3888`: Porta para elei√ß√£o de l√≠der

## Algoritmo de Consenso

### üó≥Ô∏è **Leader Election (ZAB Protocol)**

```mermaid
graph TB
    subgraph "Fase 1: Discovery"
        A[Servidor inicia] --> B[Envia LOOKING]
        B --> C[Recebe votos de outros]
        C --> D{Maioria<br/>alcan√ßada?}
        D -->|N√£o| B
        D -->|Sim| E[Torna-se LEADER]
    end
    
    subgraph "Fase 2: Synchronization"
        E --> F[Sincroniza estado<br/>com followers]
        F --> G[Confirma sincroniza√ß√£o]
    end
    
    subgraph "Fase 3: Broadcast"
        G --> H[Aceita escritas]
        H --> I[Replica para followers]
        I --> J[Aguarda ACK maioria]
        J --> K[Confirma escrita]
        K --> H
    end
```

### üìä **Quorum e Toler√¢ncia a Falhas**

| Ensemble Size | Quorum | Falhas Toleradas |
|---------------|--------|------------------|
| 1             | 1      | 0                |
| 2             | 2      | 0                |
| 3             | 2      | 1                |
| 4             | 3      | 1                |
| 5             | 3      | 2                |

**Regra**: `Quorum = (N/2) + 1`

## Opera√ß√µes com .NET (Kazoo)

### üîó **Conex√£o e Opera√ß√µes B√°sicas**
```csharp
// Equivalente em C# usando Apache.Zookeeper
using Org.Apache.Zookeeper;

public class ZookeeperClient
{
    private ZooKeeper zk;
    
    public async Task ConnectAsync()
    {
        zk = new ZooKeeper("localhost:2181,localhost:2182,localhost:2183", 
                          30000, new DefaultWatcher());
        
        // Aguardar conex√£o
        while (zk.State != ZooKeeper.States.CONNECTED)
        {
            await Task.Delay(100);
        }
    }
    
    public async Task CreateNodeAsync(string path, string data)
    {
        await zk.createAsync(path, 
                           Encoding.UTF8.GetBytes(data),
                           ZooDefs.Ids.OPEN_ACL_UNSAFE,
                           CreateMode.PERSISTENT);
    }
    
    public async Task<string> GetDataAsync(string path)
    {
        var result = await zk.getDataAsync(path, false);
        return Encoding.UTF8.GetString(result.Data);
    }
}
```

### üëÅÔ∏è **Watches e Notifica√ß√µes**
```csharp
public class ZookeeperWatcher : Watcher
{
    public override Task process(WatchedEvent @event)
    {
        Console.WriteLine($"Event: {@event.Type} on {@event.Path}");
        
        switch (@event.Type)
        {
            case Event.EventType.NodeCreated:
                Console.WriteLine($"Node created: {@event.Path}");
                break;
            case Event.EventType.NodeDataChanged:
                Console.WriteLine($"Data changed: {@event.Path}");
                break;
            case Event.EventType.NodeDeleted:
                Console.WriteLine($"Node deleted: {@event.Path}");
                break;
        }
        
        return Task.CompletedTask;
    }
}

// Uso
await zk.getDataAsync("/brokers/ids/1", new ZookeeperWatcher());
```

## Casos de Uso no Kafka

### üéØ **Service Discovery**
```
/brokers/ids/1 ‚Üí {"host":"kafka1","port":29092,"rack":"rack1"}
/brokers/ids/2 ‚Üí {"host":"kafka2","port":29092,"rack":"rack2"}
/brokers/ids/3 ‚Üí {"host":"kafka3","port":29092,"rack":"rack3"}
```

### ‚öñÔ∏è **Load Balancing**
- Clientes consultam `/brokers/ids` para descobrir brokers
- Distribuem conex√µes entre brokers dispon√≠veis
- Recebem notifica√ß√µes quando brokers saem/entram

### üîÑ **Configuration Management**
```
/config/topics/eventos-paralelos ‚Üí {
  "retention.ms": "604800000",
  "compression.type": "snappy",
  "max.message.bytes": "1000000"
}
```

### üëë **Leader Election**
- Controller election: `/controller`
- Partition leader election: `/brokers/topics/*/partitions/*/state`
- Consumer group coordination

## Monitoramento do Ensemble

### üìä **M√©tricas Importantes**
```bash
# Status do ensemble
echo "stat" | nc localhost 2181
echo "stat" | nc localhost 2182  
echo "stat" | nc localhost 2183

# Informa√ß√µes de configura√ß√£o
echo "conf" | nc localhost 2181

# Conex√µes ativas
echo "cons" | nc localhost 2181
```

### üîç **Health Checks**
```bash
# Verificar se est√° respondendo
echo "ruok" | nc localhost 2181
# Resposta esperada: "imok"

# Verificar l√≠der/follower
echo "stat" | nc localhost 2181 | grep Mode
# Resposta: Mode: leader ou Mode: follower
```

### ‚ö†Ô∏è **Alertas Cr√≠ticos**
- **Split-brain**: M√∫ltiplos l√≠deres
- **Quorum loss**: Menos de 50% dos n√≥s
- **High latency**: Sincroniza√ß√£o lenta
- **Disk space**: Logs crescendo muito

## Troubleshooting

### üö® **Problemas Comuns**

#### **Quorum Loss**
```
Error: Not enough followers to form quorum
```
**Solu√ß√£o**: Verificar conectividade de rede entre n√≥s

#### **Session Timeout**
```
Warning: Session timeout for client
```
**Solu√ß√£o**: Ajustar `sessionTimeout` ou verificar GC

#### **Split Brain**
```
Error: Multiple leaders detected
```
**Solu√ß√£o**: Reiniciar ensemble com dados consistentes

### üîß **Recovery Procedures**
1. **Backup dos dados**: `/var/lib/zookeeper/data`
2. **Verificar logs**: `/var/log/zookeeper`
3. **Reiniciar n√≥s**: Um por vez, aguardar quorum
4. **Verificar integridade**: Comparar `myid` e dados

---

**Pr√≥ximo**: [Kafka Streaming](./05-kafka-streaming.md)
