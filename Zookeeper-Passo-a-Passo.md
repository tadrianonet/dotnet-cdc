# Apache Zookeeper: Passo a Passo Pr√°tico

Este guia mostra como explorar, configurar e monitorar o Apache Zookeeper usando o ambiente Debezium que j√° temos funcionando, evoluindo para configura√ß√µes avan√ßadas e troubleshooting.

## Pr√©-requisitos

- Ambiente Debezium funcionando (do guia anterior)
- Zookeeper rodando no Docker Compose
- Conhecimento b√°sico de linha de comando
- Portas 2181, 2888, 3888 dispon√≠veis

---

## PARTE 1: Explorando o Zookeeper Existente

### Passo 1: Verificar status do Zookeeper

Primeiro, vamos verificar se o Zookeeper est√° funcionando no nosso ambiente:

```bash
# Verificar se o container est√° rodando
docker ps | grep zookeeper

# Verificar logs do Zookeeper
docker logs zookeeper
```

**O que esperar:** Container "Up" e logs mostrando "binding to port 0.0.0.0/0.0.0.0:2181"

### Passo 2: Conectar ao Zookeeper via cliente

```bash
# Verificar comandos dispon√≠veis do Zookeeper
docker exec zookeeper ls /usr/bin/ | grep zoo
```

**O que esperar:** Lista de comandos como `zookeeper-shell`, `zookeeper-server-start`, etc.

```bash
# Testar conectividade b√°sica com zookeeper-shell
docker exec zookeeper zookeeper-shell localhost:2181 <<< "ls /"
```

**Nota:** Os comandos administrativos como `stat`, `ruok`, `srvr` podem estar bloqueados por whitelist de seguran√ßa nas imagens mais recentes.

### Passo 3: Verificar integra√ß√£o Kafka-Zookeeper

Como o `zkCli.sh` n√£o est√° dispon√≠vel nesta imagem, vamos verificar se o Kafka est√° funcionando com o Zookeeper:

```bash
# Verificar se Kafka est√° funcionando com Zookeeper
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --list
```

**O que esperar:** Lista de t√≥picos existentes, confirmando que Kafka est√° se comunicando com Zookeeper.

**Explica√ß√£o:** O Kafka armazena seus metadados no Zookeeper em uma estrutura hier√°rquica similar a um sistema de arquivos.

### Passo 4: Testar funcionalidade b√°sica

Como os comandos diretos do Zookeeper est√£o limitados, vamos testar a funcionalidade atrav√©s do Kafka:

```bash
# Criar um t√≥pico de teste
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --create --topic teste-zookeeper --partitions 2 --replication-factor 1

# Listar t√≥picos para confirmar
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --list

# Ver detalhes do t√≥pico
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --describe --topic teste-zookeeper
```

**O que esperar:** T√≥pico criado com sucesso, confirmando que Zookeeper est√° armazenando os metadados corretamente.

---

## PARTE 2: Comandos Administrativos e Monitoramento

### Passo 5: Comandos de diagn√≥stico (limitados por seguran√ßa)

**Nota importante:** Nas vers√µes mais recentes das imagens Confluent, muitos comandos administrativos est√£o bloqueados por whitelist de seguran√ßa.

```bash
# Tentar comando b√°sico de sa√∫de
docker exec zookeeper bash -c "echo ruok | nc localhost 2181"
```

**O que esperar:** Mensagem "ruok is not executed because it is not in the whitelist."

### Passo 6: Monitoramento atrav√©s do Kafka

Como os comandos diretos est√£o limitados, vamos monitorar atrav√©s do comportamento do Kafka:

```bash
# Verificar se Kafka est√° saud√°vel
docker exec kafka kafka-broker-api-versions --bootstrap-server localhost:9092

# Verificar logs do Zookeeper
docker logs zookeeper | tail -10

# Verificar logs do Kafka (para ver intera√ß√£o com Zookeeper)
docker logs kafka | grep -i zookeeper | tail -5
```

### Passo 7: Explorar configura√ß√£o atual

```bash
# Ver configura√ß√£o do Zookeeper
docker exec zookeeper cat /etc/kafka/zookeeper.properties

# Ver vari√°veis de ambiente
docker exec zookeeper env | grep ZOO
```

**O que observar:**
- `ZOOKEEPER_TICK_TIME`: unidade b√°sica de tempo (2000ms)
- `ZOOKEEPER_CLIENT_PORT`: porta para clientes (2181)
- `dataDir`: diret√≥rio de dados (/var/lib/zookeeper/data)

---

## PARTE 3: Configura√ß√£o de Ensemble (Cluster)

### Passo 8: Criar ensemble Zookeeper

Vamos criar um cluster Zookeeper com 3 n√≥s. Primeiro, pare o ambiente atual:

```bash
# Parar ambiente atual
docker-compose -f docker-compose-debezium.yml down
```

Crie um novo arquivo `docker-compose-zk-cluster.yml`:

```yaml
version: '3.8'

services:
  # Zookeeper Ensemble (3 n√≥s)
  zk1:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zk1
    container_name: zk1
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_SERVERS: zk1:2888:3888;zk2:2888:3888;zk3:2888:3888
    networks:
      - zk-network

  zk2:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zk2
    container_name: zk2
    ports:
      - "2182:2181"
    environment:
      ZOOKEEPER_SERVER_ID: 2
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_SERVERS: zk1:2888:3888;zk2:2888:3888;zk3:2888:3888
    networks:
      - zk-network

  zk3:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zk3
    container_name: zk3
    ports:
      - "2183:2181"
    environment:
      ZOOKEEPER_SERVER_ID: 3
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_SERVERS: zk1:2888:3888;zk2:2888:3888;zk3:2888:3888
    networks:
      - zk-network

  # Kafka usando o ensemble
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka
    container_name: kafka
    depends_on:
      - zk1
      - zk2
      - zk3
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zk1:2181,zk2:2181,zk3:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
    networks:
      - zk-network

networks:
  zk-network:
    driver: bridge
```

**Explica√ß√£o da configura√ß√£o:**
- `ZOOKEEPER_SERVER_ID`: identificador √∫nico de cada n√≥
- `ZOOKEEPER_SERVERS`: lista de todos os servidores do ensemble
- `2888`: porta para comunica√ß√£o entre servidores
- `3888`: porta para elei√ß√£o de l√≠der

### Passo 9: Iniciar ensemble Zookeeper

```bash
# Iniciar cluster Zookeeper
docker-compose -f docker-compose-zk-cluster.yml up -d

# Verificar se todos est√£o rodando
docker-compose -f docker-compose-zk-cluster.yml ps
```

**O que esperar:** Todos os containers (zk1, zk2, zk3, kafka) devem estar "Up".

### Passo 10: Verificar forma√ß√£o do cluster

Como os comandos `stat` est√£o bloqueados, vamos verificar de forma indireta:

```bash
# Verificar se todos os containers est√£o rodando
docker-compose -f docker-compose-zk-cluster.yml ps

# Testar se Kafka consegue conectar ao ensemble
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --list
```

**O que esperar:** 
- Todos os containers "Up"
- Kafka funcionando normalmente (confirmando que ensemble est√° operacional)

### Passo 11: Testar toler√¢ncia a falhas

```bash
# Parar um n√≥ do Zookeeper para testar toler√¢ncia
docker stop zk1

# Aguardar um pouco para reelei√ß√£o
sleep 10

# Verificar se Kafka ainda funciona (confirmando que ensemble ainda tem quorum)
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --list

# Criar um t√≥pico para testar funcionalidade
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --create --topic teste-tolerancia --partitions 2 --replication-factor 1
```

**O que esperar:** 
- Kafka continua funcionando normalmente mesmo com um n√≥ parado
- T√≥pico criado com sucesso (confirmando que ensemble mant√©m quorum 2/3)

```bash
# Reiniciar o n√≥ que parou
docker start zk1

# Aguardar rejun√ß√£o ao cluster
sleep 10

# Verificar se cluster est√° completo novamente
docker-compose -f docker-compose-zk-cluster.yml ps
```

---

## PARTE 4: Opera√ß√µes Pr√°ticas com Znodes

### Passo 12: Manipular dados no Zookeeper com Python

Como o shell interativo tem limita√ß√µes, vamos usar Python com a biblioteca kazoo:

```bash
# Instalar biblioteca kazoo
pip install kazoo
```

Crie um arquivo `test_zk.py`:

```python
#!/usr/bin/env python3

from kazoo.client import KazooClient
import time

print("üîó Conectando ao ensemble Zookeeper...")
zk = KazooClient(hosts='localhost:2181,localhost:2182,localhost:2183')
zk.start()

print("‚úÖ Conectado com sucesso!")

# Criar estrutura de teste
print("üìÅ Criando estrutura de teste...")
zk.ensure_path("/aplicacao")
zk.ensure_path("/aplicacao/config")
zk.ensure_path("/aplicacao/servicos")

# Criar configura√ß√£o
config_data = '{"host":"db.exemplo.com","port":5432}'
if zk.exists("/aplicacao/config/database"):
    zk.set("/aplicacao/config/database", config_data.encode())
else:
    zk.create("/aplicacao/config/database", config_data.encode())

print("üìÑ Configura√ß√£o criada!")

# Criar servi√ßo ef√™mero
service_data = '{"host":"web1","port":8080,"status":"active"}'
service_path = "/aplicacao/servicos/web-1"

if zk.exists(service_path):
    zk.delete(service_path)

zk.create(service_path, service_data.encode(), ephemeral=True)
print("üñ•Ô∏è  Servi√ßo ef√™mero criado!")

# Listar estrutura
print("\nüìã Estrutura criada:")
children = zk.get_children("/aplicacao")
print(f"/aplicacao: {children}")

config_children = zk.get_children("/aplicacao/config")
print(f"/aplicacao/config: {config_children}")

service_children = zk.get_children("/aplicacao/servicos")
print(f"/aplicacao/servicos: {service_children}")

# Ler dados
data, stat = zk.get("/aplicacao/config/database")
print(f"\nüìÑ Dados da configura√ß√£o: {data.decode()}")

print("‚úÖ Teste conclu√≠do com sucesso!")

zk.stop()
```

Execute o script:

```bash
python test_zk.py
```

**Explica√ß√£o:**
- N√≥s persistentes permanecem at√© serem deletados
- N√≥s ef√™meros s√£o removidos quando a sess√£o termina
- Dados s√£o armazenados como bytes (JSON √© uma conven√ß√£o)

### Passo 13: Implementar watch (observador)

Crie um script Python para demonstrar watches:

```python
# Criar arquivo zk_watcher.py
cat > zk_watcher.py << 'EOF'
from kazoo.client import KazooClient
import logging
import time

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Conectar ao ensemble Zookeeper
zk = KazooClient(hosts='localhost:2181,localhost:2182,localhost:2183')
zk.start()

def watch_config_changes(event):
    """Callback executado quando configura√ß√£o muda"""
    logger.info(f"üîî Configura√ß√£o alterada: {event}")
    
    # Ler nova configura√ß√£o
    try:
        data, stat = zk.get("/aplicacao/config/database", watch=watch_config_changes)
        logger.info(f"üìÑ Nova configura√ß√£o: {data.decode('utf-8')}")
    except Exception as e:
        logger.error(f"‚ùå Erro ao ler configura√ß√£o: {e}")

def watch_services(event):
    """Callback executado quando servi√ßos mudam"""
    logger.info(f"üîî Servi√ßos alterados: {event}")
    
    # Listar servi√ßos ativos
    try:
        services = zk.get_children("/aplicacao/servicos", watch=watch_services)
        logger.info(f"üñ•Ô∏è  Servi√ßos ativos: {services}")
    except Exception as e:
        logger.error(f"‚ùå Erro ao listar servi√ßos: {e}")

# Registrar watches iniciais
try:
    # Watch na configura√ß√£o
    data, stat = zk.get("/aplicacao/config/database", watch=watch_config_changes)
    logger.info(f"üìÑ Configura√ß√£o inicial: {data.decode('utf-8')}")
    
    # Watch nos servi√ßos
    services = zk.get_children("/aplicacao/servicos", watch=watch_services)
    logger.info(f"üñ•Ô∏è  Servi√ßos iniciais: {services}")
    
    logger.info("üëÄ Monitorando mudan√ßas... (Ctrl+C para parar)")
    
    # Manter script rodando
    while True:
        time.sleep(1)
        
except KeyboardInterrupt:
    logger.info("‚èπÔ∏è  Parando monitoramento...")
finally:
    zk.stop()
EOF
```

### Passo 14: Testar watches em a√ß√£o

```bash
# Instalar depend√™ncia Python (se necess√°rio)
pip install kazoo

# Executar watcher em background
python zk_watcher.py &
WATCHER_PID=$!

# Em outro terminal, fazer mudan√ßas
docker exec -it zk1 zookeeper-shell localhost:2181 <<< '
set /aplicacao/config/database {"host":"novo-db.exemplo.com","port":5432,"ssl":true}
create -e /aplicacao/servicos/web-2 {"host":"web2","port":8080,"status":"active"}
delete /aplicacao/servicos/web-1
'

# Parar o watcher
kill $WATCHER_PID
```

**O que esperar:** O script Python deve mostrar notifica√ß√µes em tempo real das mudan√ßas.

---

## PARTE 5: Monitoramento Avan√ßado e M√©tricas

### Passo 16: Configurar monitoramento JMX

Primeiro, vamos modificar a configura√ß√£o para habilitar JMX:

```yaml
# Adicionar ao docker-compose-zk-cluster.yml na se√ß√£o environment do zk1:
KAFKA_JMX_OPTS: "-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=9999"
```

Reinicie o ambiente:

```bash
docker-compose -f docker-compose-zk-cluster.yml down
docker-compose -f docker-compose-zk-cluster.yml up -d
```

### Passo 17: Coletar m√©tricas detalhadas

Crie um script de monitoramento:

```bash
# Criar script de monitoramento
cat > monitor_zk.sh << 'EOF'
#!/bin/bash

echo "=== MONITORAMENTO ZOOKEEPER ==="
echo "Timestamp: $(date)"
echo

for i in 1 2 3; do
    port=$((2180 + i))
    echo "=== ZK$i (localhost:$port) ==="
    
    # Status b√°sico
    echo "Status:" 
    docker exec zk$i bash -c "echo stat | nc localhost 2181" | head -5
    
    # M√©tricas de performance
    echo "Lat√™ncia:"
    docker exec zk$i bash -c "echo mntr | nc localhost 2181" | grep latency
    
    echo "Throughput:"
    docker exec zk$i bash -c "echo mntr | nc localhost 2181" | grep packets
    
    echo "Conex√µes:"
    docker exec zk$i bash -c "echo mntr | nc localhost 2181" | grep connections
    
    echo "---"
done

echo "=== RESUMO DO ENSEMBLE ==="
echo "L√≠der:"
for i in 1 2 3; do
    mode=$(docker exec zk$i bash -c "echo stat | nc localhost 2181" | grep Mode | awk '{print $2}')
    echo "ZK$i: $mode"
done
EOF

chmod +x monitor_zk.sh
```

### Passo 18: Executar monitoramento cont√≠nuo

```bash
# Executar monitoramento a cada 10 segundos
watch -n 10 ./monitor_zk.sh

# Ou salvar em arquivo de log
./monitor_zk.sh > zk_metrics_$(date +%Y%m%d_%H%M%S).log
```

### Passo 19: Simular carga e observar m√©tricas

```bash
# Criar script para gerar carga
cat > zk_load_test.py << 'EOF'
from kazoo.client import KazooClient
import threading
import time
import random

def create_load(zk, thread_id):
    """Gera carga no Zookeeper"""
    for i in range(100):
        try:
            # Criar n√≥ tempor√°rio
            path = f"/load_test/thread_{thread_id}/node_{i}"
            zk.ensure_path(f"/load_test/thread_{thread_id}")
            zk.create(path, f"data_{i}".encode(), ephemeral=True, sequence=True)
            
            # Ler dados
            zk.get(path)
            
            # Pequena pausa
            time.sleep(random.uniform(0.01, 0.1))
            
        except Exception as e:
            print(f"Erro thread {thread_id}: {e}")

# Conectar ao Zookeeper
zk = KazooClient(hosts='localhost:2181,localhost:2182,localhost:2183')
zk.start()

# Criar estrutura base
zk.ensure_path("/load_test")

# Executar threads para gerar carga
threads = []
for i in range(5):
    t = threading.Thread(target=create_load, args=(zk, i))
    threads.append(t)
    t.start()

# Aguardar conclus√£o
for t in threads:
    t.join()

print("Teste de carga conclu√≠do")
zk.stop()
EOF

# Executar teste de carga
python zk_load_test.py

# Verificar m√©tricas durante/ap√≥s a carga
./monitor_zk.sh
```

---

## PARTE 6: Troubleshooting e Recupera√ß√£o

### Passo 20: Simular e resolver problemas comuns

**Problema 1: Perda de quorum**

```bash
# Parar 2 dos 3 n√≥s (maioria)
docker stop zk2 zk3

# Tentar opera√ß√£o no n√≥ restante
docker exec zk1 bash -c "echo stat | nc localhost 2181"

# Verificar logs de erro
docker logs zk1 | tail -10
```

**O que esperar:** Zk1 n√£o consegue processar opera√ß√µes (sem quorum).

**Solu√ß√£o:**
```bash
# Reiniciar pelo menos um n√≥ para restaurar quorum
docker start zk2

# Aguardar forma√ß√£o do quorum
sleep 10

# Verificar se opera√ß√µes voltaram a funcionar
docker exec zk1 bash -c "echo stat | nc localhost 2181"
```

**Problema 2: Split-brain (simula√ß√£o)**

```bash
# Verificar configura√ß√£o de rede
docker network ls
docker network inspect docker-compose-zk-cluster_zk-network

# Simular parti√ß√£o de rede (isolando um n√≥)
docker network disconnect docker-compose-zk-cluster_zk-network zk3

# Verificar comportamento
./monitor_zk.sh

# Reconectar
docker network connect docker-compose-zk-cluster_zk-network zk3
```

### Passo 21: Backup e recovery

```bash
# Criar backup dos dados
docker exec zk1 tar -czf /tmp/zk-backup.tar.gz /var/lib/zookeeper/version-2

# Copiar backup para host
docker cp zk1:/tmp/zk-backup.tar.gz ./zk-backup-$(date +%Y%m%d).tar.gz

# Simular perda de dados
docker exec zk1 rm -rf /var/lib/zookeeper/version-2/*

# Restaurar backup
docker cp ./zk-backup-$(date +%Y%m%d).tar.gz zk1:/tmp/
docker exec zk1 bash -c "cd / && tar -xzf /tmp/zk-backup-*.tar.gz"

# Reiniciar para aplicar
docker restart zk1
```

### Passo 22: An√°lise de logs detalhada

```bash
# Verificar logs de cada n√≥
for i in 1 2 3; do
    echo "=== LOGS ZK$i ==="
    docker logs zk$i | grep -E "(ERROR|WARN|Election|Leader)" | tail -5
    echo
done

# Monitorar logs em tempo real
docker logs -f zk1 &
docker logs -f zk2 &
docker logs -f zk3 &

# Parar monitoramento (Ctrl+C)
```

---

## PARTE 7: Integra√ß√£o com Aplica√ß√µes

### Passo 23: Implementar descoberta de servi√ßos

```python
# Criar service_discovery.py
cat > service_discovery.py << 'EOF'
from kazoo.client import KazooClient
import json
import time
import threading

class ServiceRegistry:
    def __init__(self, zk_hosts):
        self.zk = KazooClient(hosts=zk_hosts)
        self.zk.start()
        self.services = {}
        
    def register_service(self, service_name, host, port, metadata=None):
        """Registra um servi√ßo no Zookeeper"""
        service_data = {
            'host': host,
            'port': port,
            'metadata': metadata or {},
            'registered_at': time.time()
        }
        
        # Criar caminho do servi√ßo
        service_path = f"/services/{service_name}"
        self.zk.ensure_path(service_path)
        
        # Registrar inst√¢ncia (n√≥ ef√™mero sequencial)
        instance_path = f"{service_path}/instance_"
        actual_path = self.zk.create(
            instance_path,
            json.dumps(service_data).encode(),
            ephemeral=True,
            sequence=True
        )
        
        print(f"‚úÖ Servi√ßo {service_name} registrado em {actual_path}")
        return actual_path
        
    def discover_services(self, service_name):
        """Descobre inst√¢ncias de um servi√ßo"""
        service_path = f"/services/{service_name}"
        
        try:
            instances = self.zk.get_children(service_path)
            services = []
            
            for instance in instances:
                instance_path = f"{service_path}/{instance}"
                data, stat = self.zk.get(instance_path)
                service_info = json.loads(data.decode())
                services.append(service_info)
                
            return services
        except Exception as e:
            print(f"‚ùå Erro ao descobrir servi√ßos: {e}")
            return []
            
    def watch_service(self, service_name, callback):
        """Monitora mudan√ßas em um servi√ßo"""
        service_path = f"/services/{service_name}"
        
        def watcher(event):
            print(f"üîî Mudan√ßa no servi√ßo {service_name}: {event}")
            services = self.discover_services(service_name)
            callback(services)
            
            # Re-registrar watch
            try:
                self.zk.get_children(service_path, watch=watcher)
            except:
                pass
                
        # Registrar watch inicial
        try:
            self.zk.get_children(service_path, watch=watcher)
        except:
            self.zk.ensure_path(service_path)
            self.zk.get_children(service_path, watch=watcher)

# Exemplo de uso
if __name__ == "__main__":
    registry = ServiceRegistry('localhost:2181,localhost:2182,localhost:2183')
    
    # Simular registro de servi√ßos
    def simulate_service(name, host, port):
        path = registry.register_service(name, host, port, {'version': '1.0'})
        time.sleep(30)  # Simular servi√ßo rodando
        print(f"üî¥ Servi√ßo {name} finalizando...")
        
    # Registrar alguns servi√ßos
    threading.Thread(target=simulate_service, args=('web-api', 'web1', 8080)).start()
    threading.Thread(target=simulate_service, args=('web-api', 'web2', 8080)).start()
    threading.Thread(target=simulate_service, args=('database', 'db1', 5432)).start()
    
    # Descobrir servi√ßos
    time.sleep(2)
    web_services = registry.discover_services('web-api')
    print(f"üîç Servi√ßos web-api encontrados: {web_services}")
    
    # Monitorar mudan√ßas
    def on_service_change(services):
        print(f"üìä Servi√ßos web-api atualizados: {len(services)} inst√¢ncias")
        
    registry.watch_service('web-api', on_service_change)
    
    # Manter rodando
    time.sleep(60)
EOF

# Executar exemplo
python service_discovery.py
```

### Passo 24: Configura√ß√£o distribu√≠da

```python
# Criar config_manager.py
cat > config_manager.py << 'EOF'
from kazoo.client import KazooClient
import json
import threading
import time

class ConfigManager:
    def __init__(self, zk_hosts, app_name):
        self.zk = KazooClient(hosts=zk_hosts)
        self.zk.start()
        self.app_name = app_name
        self.config_path = f"/config/{app_name}"
        self.local_config = {}
        self.callbacks = []
        
        # Garantir que caminho existe
        self.zk.ensure_path(self.config_path)
        
        # Carregar configura√ß√£o inicial
        self._load_config()
        
    def _load_config(self):
        """Carrega configura√ß√£o do Zookeeper"""
        try:
            children = self.zk.get_children(self.config_path, watch=self._config_watcher)
            new_config = {}
            
            for child in children:
                child_path = f"{self.config_path}/{child}"
                data, stat = self.zk.get(child_path)
                try:
                    new_config[child] = json.loads(data.decode())
                except:
                    new_config[child] = data.decode()
                    
            self.local_config = new_config
            print(f"üìÑ Configura√ß√£o carregada: {self.local_config}")
            
            # Notificar callbacks
            for callback in self.callbacks:
                callback(self.local_config)
                
        except Exception as e:
            print(f"‚ùå Erro ao carregar configura√ß√£o: {e}")
            
    def _config_watcher(self, event):
        """Watch para mudan√ßas na configura√ß√£o"""
        print(f"üîî Configura√ß√£o alterada: {event}")
        self._load_config()
        
    def get(self, key, default=None):
        """Obt√©m valor de configura√ß√£o"""
        return self.local_config.get(key, default)
        
    def set(self, key, value):
        """Define valor de configura√ß√£o"""
        config_key_path = f"{self.config_path}/{key}"
        
        try:
            data = json.dumps(value) if isinstance(value, (dict, list)) else str(value)
            
            if self.zk.exists(config_key_path):
                self.zk.set(config_key_path, data.encode())
            else:
                self.zk.create(config_key_path, data.encode())
                
            print(f"‚úÖ Configura√ß√£o {key} atualizada")
        except Exception as e:
            print(f"‚ùå Erro ao definir configura√ß√£o: {e}")
            
    def on_config_change(self, callback):
        """Registra callback para mudan√ßas"""
        self.callbacks.append(callback)

# Exemplo de uso
if __name__ == "__main__":
    # Criar gerenciador de configura√ß√£o
    config = ConfigManager('localhost:2181,localhost:2182,localhost:2183', 'minha-app')
    
    # Definir configura√ß√µes iniciais
    config.set('database_url', 'postgresql://user:pass@db:5432/myapp')
    config.set('redis_url', 'redis://redis:6379/0')
    config.set('log_level', 'INFO')
    config.set('features', {'new_ui': True, 'beta_api': False})
    
    # Registrar callback para mudan√ßas
    def on_config_update(new_config):
        print(f"üîÑ Aplica√ß√£o recebeu nova configura√ß√£o: {new_config}")
        
    config.on_config_change(on_config_update)
    
    # Simular aplica√ß√£o rodando
    print("üöÄ Aplica√ß√£o iniciada, monitorando configura√ß√µes...")
    
    # Em outro terminal, voc√™ pode alterar configura√ß√µes:
    # docker exec -it zk1 zookeeper-shell localhost:2181
    # set /config/minha-app/log_level "DEBUG"
    
    try:
        while True:
            print(f"üìä Database URL: {config.get('database_url')}")
            print(f"üìä Log Level: {config.get('log_level')}")
            time.sleep(10)
    except KeyboardInterrupt:
        print("‚èπÔ∏è  Parando aplica√ß√£o...")
EOF

# Executar gerenciador de configura√ß√£o
python config_manager.py &
CONFIG_PID=$!

# Testar mudan√ßa de configura√ß√£o
sleep 5
docker exec -it zk1 zookeeper-shell localhost:2181 <<< 'set /config/minha-app/log_level "DEBUG"'

# Parar ap√≥s teste
sleep 10
kill $CONFIG_PID
```

---

## PARTE 8: Limpeza e Pr√≥ximos Passos

### Passo 25: Limpeza do ambiente

```bash
# Parar todos os processos Python
pkill -f python

# Parar ambiente Zookeeper
docker-compose -f docker-compose-zk-cluster.yml down

# Limpar dados (opcional)
docker-compose -f docker-compose-zk-cluster.yml down -v

# Voltar ao ambiente Debezium original (se necess√°rio)
docker-compose -f docker-compose-debezium.yml up -d
```

### Passo 26: Scripts de automa√ß√£o

```bash
# Criar script de deploy completo
cat > deploy_zk_cluster.sh << 'EOF'
#!/bin/bash

echo "üöÄ Iniciando deploy do cluster Zookeeper..."

# Parar ambiente anterior
docker-compose -f docker-compose-debezium.yml down 2>/dev/null

# Iniciar novo cluster
docker-compose -f docker-compose-zk-cluster.yml up -d

# Aguardar inicializa√ß√£o
echo "‚è≥ Aguardando inicializa√ß√£o..."
sleep 30

# Verificar sa√∫de do cluster
echo "üîç Verificando sa√∫de do cluster..."
for i in 1 2 3; do
    status=$(docker exec zk$i bash -c "echo ruok | nc localhost 2181" 2>/dev/null)
    if [ "$status" = "imok" ]; then
        echo "‚úÖ ZK$i: OK"
    else
        echo "‚ùå ZK$i: FALHA"
    fi
done

# Verificar elei√ß√£o de l√≠der
echo "üëë Status do ensemble:"
for i in 1 2 3; do
    mode=$(docker exec zk$i bash -c "echo stat | nc localhost 2181" 2>/dev/null | grep Mode | awk '{print $2}')
    echo "ZK$i: $mode"
done

echo "‚úÖ Deploy conclu√≠do!"
EOF

chmod +x deploy_zk_cluster.sh
```

---

## Resumo do que foi demonstrado

1. **Explora√ß√£o do Zookeeper**: verifica√ß√£o de funcionamento atrav√©s do Kafka
2. **Limita√ß√µes de seguran√ßa**: comandos administrativos bloqueados por whitelist
3. **Cluster (Ensemble)**: configura√ß√£o de 3 n√≥s, toler√¢ncia a falhas testada
4. **Opera√ß√µes pr√°ticas**: cria√ß√£o de znodes via Python/kazoo, watches funcionais
5. **Integra√ß√£o com aplica√ß√µes**: descoberta de servi√ßos, configura√ß√£o distribu√≠da
6. **Monitoramento indireto**: atrav√©s de logs e comportamento do Kafka
7. **Automa√ß√£o**: scripts Python para opera√ß√µes complexas

## Limita√ß√µes encontradas e solu√ß√µes

### Comandos administrativos bloqueados
- **Problema**: `stat`, `ruok`, `srvr` bloqueados por whitelist
- **Solu√ß√£o**: Monitoramento atrav√©s do comportamento do Kafka e logs

### zkCli.sh n√£o dispon√≠vel
- **Problema**: Cliente de linha de comando n√£o encontrado
- **Solu√ß√£o**: Uso da biblioteca Python kazoo para opera√ß√µes

### Abordagem alternativa validada
- **Funciona**: Ensemble de 3 n√≥s com toler√¢ncia a falhas
- **Funciona**: Opera√ß√µes com znodes via Python
- **Funciona**: Watches e descoberta de servi√ßos
- **Funciona**: Configura√ß√£o distribu√≠da

## Conceitos fundamentais aprendidos

- **Coordena√ß√£o distribu√≠da**: como Zookeeper sincroniza m√∫ltiplos sistemas
- **Consist√™ncia forte**: garantias ACID em ambiente distribu√≠do
- **Elei√ß√£o de l√≠der**: algoritmos de consenso em a√ß√£o
- **Watches**: notifica√ß√µes em tempo real de mudan√ßas
- **Ensemble**: alta disponibilidade com quorum
- **Znodes**: modelo de dados hier√°rquico
- **Sess√µes**: gerenciamento de conex√µes e detec√ß√£o de falhas

## Aplica√ß√µes pr√°ticas

- **Kafka**: coordena√ß√£o de brokers, metadados, elei√ß√£o de controller
- **Descoberta de servi√ßos**: registro din√¢mico de microservi√ßos
- **Configura√ß√£o distribu√≠da**: centraliza√ß√£o de configura√ß√µes com notifica√ß√µes
- **Locks distribu√≠dos**: coordena√ß√£o de recursos compartilhados
- **Elei√ß√£o de l√≠der**: coordena√ß√£o de processos distribu√≠dos

Este ambiente Zookeeper est√° pronto para uso em produ√ß√£o e fornece uma base s√≥lida para entender sistemas distribu√≠dos e coordena√ß√£o de clusters.

**Pr√≥ximo passo: Apache Kafka** - a plataforma de streaming que utiliza toda essa coordena√ß√£o do Zookeeper! üöÄ
